{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import mlflow\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tabulate import tabulate\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273f65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceMemUsage:\n",
    "    \"\"\"Down-casts numeric cols in-place to save RAM.\"\"\"\n",
    "    def __call__(self, df: pd.DataFrame):\n",
    "        for col in df:\n",
    "            if df[col].dtype == 'float64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "            elif df[col].dtype == 'int64':\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        return df\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Replaces categories by their train-set frequency (0-1 float).\n",
    "    If `cols` is None we auto-select every *non-numeric* column.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols=None): self.cols = cols\n",
    "    def fit(self, X, y=None):\n",
    "        if self.cols is None:\n",
    "            self.cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "        self.maps_ = {c: X[c].value_counts(normalize=True) for c in self.cols}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for c, m in self.maps_.items():\n",
    "            X[c] = X[c].map(m).astype('float32')\n",
    "        return X[self.cols]          # keep only encoded cols\n",
    "\n",
    "class PurgedKFold(StratifiedKFold):\n",
    "    \"\"\"Time-based CV that removes an embargo window around the val period.\"\"\"\n",
    "    def __init__(self, n_splits=5, embargo_pct=0.01, **kw):\n",
    "        super().__init__(n_splits=n_splits, shuffle=False, **kw)\n",
    "        self.embargo_pct = embargo_pct\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        # X must be sorted by time already\n",
    "        n = len(X); embargo = int(n * self.embargo_pct)\n",
    "        fold_sizes = np.full(self.n_splits, n // self.n_splits, dtype=int)\n",
    "        fold_sizes[: n % self.n_splits] += 1\n",
    "        idx = 0\n",
    "        for sz in fold_sizes:\n",
    "            start, stop = idx, idx + sz\n",
    "            test_idx = np.arange(start, stop)\n",
    "            train_idx = np.r_[0:max(0,start-embargo), stop+embargo:n]\n",
    "            idx = stop\n",
    "            yield train_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5c34a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id  = pd.read_csv('../datasets/train_identity.csv')\n",
    "df_trx = pd.read_csv('../datasets/train_transaction.csv')\n",
    "df     = pd.merge(df_trx, df_id, on='TransactionID', how='left')\n",
    "df     = ReduceMemUsage()(df)           # saves ≈40 % RAM\n",
    "\n",
    "# Chronological split (80 / 20)\n",
    "cutoff  = df.TransactionDT.quantile(.8)\n",
    "train   = df[df.TransactionDT <= cutoff].reset_index(drop=True)\n",
    "valid   = df[df.TransactionDT  > cutoff].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d6a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr = train.drop('isFraud',axis=1), train.isFraud.values\n",
    "X_va, y_va = valid.drop('isFraud',axis=1), valid.isFraud.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb3e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── feature_blocks.py ─────────────────────────────────────────────────────────\n",
    "import re, numpy as np, pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "EMAIL_MAP = {  # collapses tiny domains\n",
    "    'gmail.com':'google', 'gmail':'google',\n",
    "    'yahoo.com':'yahoo', 'yahoo.com.mx':'yahoo', 'ymail.com':'yahoo',\n",
    "    'outlook.com':'microsoft', 'hotmail.com':'microsoft', 'live.com':'microsoft'\n",
    "}\n",
    "START_DATE = pd.to_datetime('2017-12-01')\n",
    "\n",
    "class BasicTimeAmt(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['log_amt'] = np.log1p(X['TransactionAmt'])\n",
    "        dt           = START_DATE + pd.to_timedelta(X['TransactionDT'], unit='s')\n",
    "        X['dow']     = dt.dt.dayofweek.astype('int8')\n",
    "        X['hour']    = dt.dt.hour.astype('int8')\n",
    "        X['is_we']   = (X['dow']>=5).astype('int8')\n",
    "        return X[['log_amt','dow','hour','is_we']]\n",
    "\n",
    "class EmailDomain(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=('P_emaildomain', 'R_emaildomain')):  # noqa\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):  # nothing to learn\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_new = pd.DataFrame(index=X.index)\n",
    "        for c in self.cols:\n",
    "            if c not in X.columns:                 # ← guard against KeyError\n",
    "                continue\n",
    "            \n",
    "            tmp = (\n",
    "                X[c].str.lower()\n",
    "                    .str.extract(r'([A-Za-z0-9.-]+\\.[A-Za-z]{2,4})', expand=False)\n",
    "                    .map(EMAIL_MAP)\n",
    "                    .fillna('other')\n",
    "                    .astype('category')\n",
    "            )\n",
    "            X_new[c] = tmp\n",
    "        return X_new\n",
    "\n",
    "class CardFreqAmt(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Ratio of amount to historical mean per card1 + overall freq of card1.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        self.card_mean_ = X.groupby('card1')['TransactionAmt'].mean()\n",
    "        self.card_freq_ = X['card1'].value_counts(normalize=True)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['card1_mean'] = X['card1'].map(self.card_mean_)\n",
    "        X['amt_over_mean'] = X['TransactionAmt'] / X['card1_mean']\n",
    "        X['card1_freq']  = X['card1'].map(self.card_freq_)\n",
    "        return X[['amt_over_mean','card1_freq']]\n",
    "\n",
    "# Assembling all blocks\n",
    "class FeatureAssembler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Add engineered features *on top of* the raw dataframe so downstream\n",
    "    transformers still see the original columns.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.blocks = [BasicTimeAmt(), EmailDomain(), CardFreqAmt()]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for b in self.blocks:\n",
    "            b.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_aug = X.copy()\n",
    "        for b in self.blocks:\n",
    "            X_aug = pd.concat([X_aug, b.transform(X)], axis=1)\n",
    "        # optional: drop duplicate columns that might appear\n",
    "        X_aug = X_aug.loc[:, ~X_aug.columns.duplicated()]\n",
    "        return X_aug\n",
    "    \n",
    "class SparseDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=0.75): \n",
    "        self.thresh = thresh\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.keep_ = [c for c in X.columns if X[c].isna().mean() < self.thresh]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.keep_]\n",
    "    \n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Remove column if it is present.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):      # nothing to learn\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e71a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with >75 % NaN\n",
    "nan_thresh = 0.75\n",
    "keep_cols  = [c for c,p in (train.isna().mean()).items() if p < nan_thresh]\n",
    "\n",
    "# Remove highly correlated numeric (>0.95)\n",
    "corr = train[keep_cols].select_dtypes(include=['number']).corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "cor_cols = [c for c in upper.columns if any(upper[c] > .95)]\n",
    "keep_cols = list(set(keep_cols) - set(cor_cols))\n",
    "\n",
    "num_cols  = train[keep_cols].select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols  = [c for c in keep_cols if c not in num_cols and c!='isFraud']\n",
    "\n",
    "# Exclude target\n",
    "target = \"isFraud\"\n",
    "drops = [\"TransactionID\"] + [target, ]\n",
    "nan_thresh = 0.75\n",
    "num_cols  = [c for c in num_cols  if c not in drops]\n",
    "cat_cols  = [c for c in cat_cols if c not in drops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c6bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/24 22:21:07 INFO mlflow.tracking.fluent: Experiment with name 'IEEE-CIS Trials' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: trial-0...\n",
      "\tdelta: {}\n",
      "\tBuilding pipeline...\n",
      "\tFitting...\n",
      "\tEvaluating...\n",
      "\tLogging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 22:26:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrial trial-0: AUC=0.9230 | PR-AUC=0.5826\n",
      "🏃 View run trial-0 at: http://127.0.0.1:5000/#/experiments/377797843707944316/runs/d081a3c81932419587069b25c627e222\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/377797843707944316\n",
      "Trial: trial-1...\n",
      "\tdelta: {'imputer_num_strategy': 'constant', 'imputer_num_value': -999}\n",
      "\tBuilding pipeline...\n",
      "\tFitting...\n",
      "\tEvaluating...\n",
      "\tLogging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 22:30:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrial trial-1: AUC=0.9229 | PR-AUC=0.5823\n",
      "🏃 View run trial-1 at: http://127.0.0.1:5000/#/experiments/377797843707944316/runs/76441eae75a34c3c895162434da5b47c\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/377797843707944316\n",
      "Trial: trial-2...\n",
      "\tdelta: {'feat_eng': False}\n",
      "\tBuilding pipeline...\n",
      "\tFitting...\n",
      "\tEvaluating...\n",
      "\tLogging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 22:35:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrial trial-2: AUC=0.9186 | PR-AUC=0.5741\n",
      "🏃 View run trial-2 at: http://127.0.0.1:5000/#/experiments/377797843707944316/runs/771451b8c00e43c0bc40800429ca091d\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/377797843707944316\n",
      "Trial: trial-3...\n",
      "\tdelta: {'scaler': 'standard'}\n",
      "\tBuilding pipeline...\n",
      "\tFitting...\n",
      "\tEvaluating...\n",
      "\tLogging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 22:40:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrial trial-3: AUC=0.9230 | PR-AUC=0.5826\n",
      "🏃 View run trial-3 at: http://127.0.0.1:5000/#/experiments/377797843707944316/runs/c3b2567256a94186bbe938dd1292b7f7\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/377797843707944316\n",
      "Trial: trial-4...\n",
      "\tdelta: {'xgb_params': {'learning_rate': 0.05, 'n_estimators': 1200}}\n",
      "\tBuilding pipeline...\n",
      "\tFitting...\n",
      "\tEvaluating...\n",
      "\tLogging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 22:44:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrial trial-4: AUC=0.9217 | PR-AUC=0.5897\n",
      "🏃 View run trial-4 at: http://127.0.0.1:5000/#/experiments/377797843707944316/runs/1982c21d732c41dd9c0adbc669b7f706\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/377797843707944316\n",
      "Trial: trial-5...\n",
      "\tdelta: {'model': 'lgb'}\n",
      "\tBuilding pipeline...\n",
      "\tFitting...\n",
      "\tEvaluating...\n",
      "\tLogging...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 22:47:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrial trial-5: AUC=0.9160 | PR-AUC=0.5312\n",
      "🏃 View run trial-5 at: http://127.0.0.1:5000/#/experiments/377797843707944316/runs/f11b648953ca48578863ef34da13b2e4\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/377797843707944316\n"
     ]
    }
   ],
   "source": [
    "# Base parameters\n",
    "base_params = {\n",
    "    # preprocessing\n",
    "    \"missing_threshold\"     : 0.75,\n",
    "    \"imputer_num_strategy\"  : \"median\",\n",
    "    \"imputer_num_value\"     : -999,\n",
    "    \"imputer_cat_strategy\"  : \"most_frequent\",\n",
    "    \"scaler\"                : \"robust\",          # robust / standard / none\n",
    "    \"use_freq_encoder\"      : True,\n",
    "    \"feat_eng\"              : True,\n",
    "    \"sparse_drop\"           : True,\n",
    "\n",
    "    # model family to run\n",
    "    \"model\" : \"xgb\",                            # lgb / xgb\n",
    "\n",
    "    # model-specific defaults\n",
    "    \"lgb_params\": dict(\n",
    "        n_estimators=600, num_leaves=64, max_depth=-1,\n",
    "        subsample=0.9, colsample_bytree=0.7,\n",
    "        learning_rate=0.05, objective=\"binary\",\n",
    "        class_weight=\"balanced\", random_state=42, verbose=-1,\n",
    "    ),\n",
    "    \"xgb_params\": dict(\n",
    "        n_estimators=2000, max_depth=12, learning_rate=0.02,\n",
    "        subsample=0.8, colsample_bytree=0.5,\n",
    "        eval_metric=\"auc\", tree_method=\"hist\", random_state=42,\n",
    "        # scale_pos_weight will be filled from data\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Trials\n",
    "trials = [\n",
    "    {'name': 'trial-0', 'delta': {}},  # ➊ baseline – exactly base_params\n",
    "    {'name': 'trial-1', 'delta': {\"imputer_num_strategy\": \"constant\", \"imputer_num_value\": -999}},\n",
    "    {'name': 'trial-2', 'delta': {\"feat_eng\": False}},\n",
    "    {'name': 'trial-3', 'delta': {\"scaler\": \"standard\"}},\n",
    "    {'name': 'trial-4', 'delta': {\"xgb_params\": {\"learning_rate\": 0.05, \"n_estimators\": 1200}}},\n",
    "    {'name': 'trial-5', 'delta': {\"model\": \"lgb\"}},                                   # switch model family\n",
    "]\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def deep_update(orig: dict, updates: dict) -> dict:\n",
    "    \"\"\"Recursively merge *updates* into *orig* (returns a new dict).\"\"\"\n",
    "    out = copy.deepcopy(orig)\n",
    "    for k, v in updates.items():\n",
    "        if isinstance(v, dict):\n",
    "            out[k] = deep_update(out.get(k, {}), v)\n",
    "        else:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "def build_preproc(p: dict):\n",
    "    # numeric\n",
    "    imputer_num = SimpleImputer(\n",
    "        strategy=p[\"imputer_num_strategy\"], fill_value=p[\"imputer_num_value\"]\n",
    "    )\n",
    "    scaler = {\n",
    "        \"robust\":   RobustScaler(),\n",
    "        \"standard\": StandardScaler(),\n",
    "        \"none\":     \"passthrough\",\n",
    "    }[p[\"scaler\"]]\n",
    "    num_pipe = Pipeline([(\"impute\", imputer_num), (\"scale\", scaler)])\n",
    "\n",
    "    # categorical\n",
    "    cat_steps = []\n",
    "    if p[\"use_freq_encoder\"]:\n",
    "        cat_steps.append((\"freq\", FrequencyEncoder()))\n",
    "    cat_steps.append((\"impute\", SimpleImputer(strategy=p[\"imputer_cat_strategy\"])))\n",
    "    cat_pipe = Pipeline(cat_steps)\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        (\"num\", num_pipe, selector(dtype_include=np.number)),\n",
    "        (\"cat\", cat_pipe, selector(dtype_exclude=np.number)),\n",
    "    ])\n",
    "\n",
    "def build_model_pipe(p: dict):\n",
    "    model_name = p[\"model\"]\n",
    "    if model_name == \"lgb\":\n",
    "        clf = LGBMClassifier(**p[\"lgb_params\"])\n",
    "    elif model_name == \"xgb\":\n",
    "        clf = XGBClassifier(**p[\"xgb_params\"])\n",
    "    else:\n",
    "        raise ValueError(\"model must be 'lgb' or 'xgb'\")\n",
    "\n",
    "    steps = [\n",
    "        (\"drop_cols\", DropColumns([\"isFraud\", \"TransactionID\"])),\n",
    "    ]\n",
    "    if p[\"feat_eng\"]:\n",
    "        steps.append((\"feat\", FeatureAssembler()))\n",
    "    if p[\"sparse_drop\"]:\n",
    "        steps.append((\"sparse\", SparseDropper(p[\"missing_threshold\"])))\n",
    "    steps += [\n",
    "        (\"union\", build_preproc(p)),\n",
    "        (\"vt\",    VarianceThreshold(0.0)),\n",
    "        (\"clf\",   clf),\n",
    "    ]\n",
    "    return Pipeline(steps)\n",
    "\n",
    "def flatten_dict(d, parent_key=\"\", sep=\"/\"):\n",
    "    \"\"\"Turn nested dicts into a flat {key1/key2: value} form for MLflow.\"\"\"\n",
    "    items = {}\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.update(flatten_dict(v, new_key, sep=sep))\n",
    "        else:\n",
    "            items[new_key] = v\n",
    "    return items\n",
    "\n",
    "# class-imbalance factor for *all* xgb trials\n",
    "base_spw = (len(train) - train.isFraud.sum()) / train.isFraud.sum()\n",
    "\n",
    "# Experiment Tracking\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"IEEE-CIS Trials\")\n",
    "mlflow.sklearn.autolog(log_input_examples=False, silent=True)\n",
    "\n",
    "# Run trials\n",
    "for trial in trials:\n",
    "    run_name = trial['name']\n",
    "    delta = trial['delta']\n",
    "\n",
    "    print(f'Trial: {run_name}...')\n",
    "    print(f'\\tdelta: {delta}')\n",
    "    p = deep_update(base_params, delta)\n",
    "\n",
    "    if p[\"model\"] == \"xgb\":\n",
    "        p[\"xgb_params\"][\"scale_pos_weight\"] = base_spw\n",
    "\n",
    "    # Model training\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params(flatten_dict(p))   # helper below\n",
    "\n",
    "        print(f'\\tBuilding pipeline...')\n",
    "        pipe = build_model_pipe(p)\n",
    "\n",
    "        print(f'\\tFitting...')\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        print(f'\\tEvaluating...')\n",
    "        proba = pipe.predict_proba(X_va)[:, 1]\n",
    "        auc   = roc_auc_score(y_va, proba)\n",
    "        ap    = average_precision_score(y_va, proba)\n",
    "        mlflow.log_metric(\"valid_auc\", auc)\n",
    "        mlflow.log_metric(\"valid_pr_auc\", ap)\n",
    "\n",
    "        print(f'\\tLogging...')\n",
    "        fpr, tpr, _ = roc_curve(y_va, proba)\n",
    "        plt.figure(); plt.plot(fpr, tpr); plt.title(\"ROC\"); mlflow.log_figure(plt.gcf(),\"roc.png\"); plt.close()\n",
    "        prec, rec, _ = precision_recall_curve(y_va, proba)\n",
    "        plt.figure(); plt.plot(rec, prec); plt.title(\"PR\"); mlflow.log_figure(plt.gcf(),\"pr.png\"); plt.close()\n",
    "\n",
    "        mlflow.sklearn.log_model(pipe, artifact_path=\"model\")\n",
    "\n",
    "        print(f\"\\tTrial {run_name}: AUC={auc:.4f} | PR-AUC={ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cb9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsel-fraud-det",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
